# LLM-generative-AI-based-assistant-with-RAG-embedding-models-and-a-vector-database.

#### This project involved building a generative AI-based query assistant using Python and LangChain. The assistant runs via a web app, using LLM in its standard format, applying prompt engineering with RAG, including the use of embedding models and a vector database. It's an excellent project for anyone wanting to understand what Artificial Intelligence really is and how a generative AI app actually works.
